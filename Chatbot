
pip install openai chromadb

import json
import openai
import chromadb
from chromadb.utils import embedding_functions

# Inicializar cliente OpenAI
client = openai()

# Cargar datos desde JSON
with open("mis_datos.json", "r", encoding="utf-8") as f:
    docs = json.load(f)

# Inicializar Chroma con embeddings de OpenAI
chroma_client = chromadb.Client()
embedding_function = embedding_functions.OpenAIEmbeddingFunction(
    api_key=client.api_key,
    model_name="text-embedding-3-small"
)

collection = chroma_client.create_collection(
    name="mi_bd",
    embedding_function=embedding_function
)

# Cargar documentos a Chroma
for doc in docs:
    collection.add(
        ids=[str(doc["id"])],
        documents=[doc["content"]],
        metadatas=[{"title": doc["title"]}]
    )

print("‚úÖ Base vectorial cargada con tus datos.")

# --- Funci√≥n para responder preguntas ---
def responder_pregunta(pregunta):
    # Buscar documentos relevantes
    resultados = collection.query(
        query_texts=[pregunta],
        n_results=3
    )

    contexto = "\n".join(resultados["documents"][0])

    prompt = f"""
    Responde SOLO bas√°ndote en el siguiente contexto.
    Si no encuentras la respuesta en el contexto, di: 
    "No tengo esa informaci√≥n".

    Contexto:
    {contexto}

    Pregunta: {pregunta}
    Respuesta:
    """

    respuesta = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "system", "content": prompt}]
    )

    return respuesta.choices[0].message.content.strip()

# --- Modo interactivo ---
print("\nü§ñ Chatbot iniciado. Escribe 'salir' para terminar.\n")

while True:
    query = input("T√∫: ")
    if query.lower() in ["salir", "exit", "quit"]:
        break
    respuesta = responder_pregunta(query)
    print(f"Bot: {respuesta}\n")
